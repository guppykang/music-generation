{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {}\n",
    "config['epochs'] = 2\n",
    "config['temperature'] = 1\n",
    "config['num_neurons'] = 100\n",
    "config['num_layers'] = 1\n",
    "config['input_dim'] = None\n",
    "config['learning_rate'] = 0.001\n",
    "config['saved_path'] = 'Saved_weights.pth'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if your system supports CUDA\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "# Setup GPU optimization if CUDA is supported\n",
    "if use_cuda:\n",
    "    computing_device = torch.device(\"cuda\")\n",
    "    extras = {\"num_workers\": 1, \"pin_memory\": True}\n",
    "    print(\"CUDA is supported\")\n",
    "else: # Otherwise, train on the CPU\n",
    "    computing_device = torch.device(\"cpu\")\n",
    "    extras = False\n",
    "    print(\"CUDA NOT supported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[')', '_', 'Y', 'J', 'D', '.', 'j', '0', '1', '*', 'h', '{', 'T', 'K', '(', '~', ',', 'I', '=', 'Z', 'x', 'C', 'X', '#', 'V', '7', 'q', 'N', 'k', '}', '+', 'g', 'y', 'E', 'o', 'n', 'O', '^', 'R', '8', 's', '-', ']', 't', ':', '<', 'H', 'S', 'e', '4', 'B', 'i', '\\n', 'L', 'W', 'P', '\\\\', 'v', 'Q', '\"', '2', 'U', '6', '5', 'f', 'w', 'd', 'z', '?', 'A', '[', 'G', 'M', 'F', '\\t', 'b', 'l', 'c', '3', '@', \"'\", '&', '/', '>', '|', '9', '!', 'a', 'u', ' ', 'p', 'r', 'm']\n"
     ]
    }
   ],
   "source": [
    "train_file = open('train.txt', 'r')\n",
    "train_file = train_file.read()\n",
    "train_songs = []\n",
    "\n",
    "val_file = open('val.txt', 'r')\n",
    "val_file = val_file.read()\n",
    "val_songs = []\n",
    "\n",
    "test_file = open('test.txt', 'r')\n",
    "test_file = test_file.read()\n",
    "test_songs = []\n",
    "\n",
    "#split the songs into their own strings, while including start and end tags\n",
    "for song in train_file.split('<start>')[1:]:\n",
    "    #remove \\n after <end> tag\n",
    "    train_songs.append('<start>' + song[:-1])\n",
    "    \n",
    "for song in val_file.split('<start>')[1:]:\n",
    "    #remove \\n after <end> tag\n",
    "    val_songs.append('<start>' + song[:-1])\n",
    "\n",
    "for song in test_file.split('<start>')[1:]:\n",
    "    #remove \\n after <end> tag\n",
    "    test_songs.append('<start>' + song[:-1])\n",
    "    \n",
    "    \n",
    "unique_characters = list(set(train_file))\n",
    "config['input_dim'] = len(unique_characters)\n",
    "\n",
    "#create one hot encodings for each unique character in the alphabet of the training data\n",
    "one_hot_dict_encode = {}\n",
    "one_hot_dict_decode = {}\n",
    "index = 0\n",
    "for unique_character in unique_characters:\n",
    "    current_encoding = np.zeros(len(unique_characters))\n",
    "    current_encoding[index] = 1\n",
    "    \n",
    "    one_hot_dict_encode[unique_character] = current_encoding\n",
    "    one_hot_dict_decode[tuple(current_encoding)] = unique_character\n",
    "    \n",
    "    index += 1\n",
    "\n",
    "\n",
    "print(unique_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-4-4e03f794e53f>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-4-4e03f794e53f>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    model =\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "hidden_state = torch.zeros((config['num_layers'], 1, config['input_dim'])).to(computing_device)\n",
    "cell_state = torch.zeros((config['num_layers'], 1, config['input_dim'])).to(computing_device)\n",
    "hidden = (hidden_state, cell_state)\n",
    "\n",
    "model = Lstm(config['input_dim'], config['num_neurons'], config['num_layers'], hidden)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=config['learning_rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO : dataset and dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start>\\nX:1\\nT: La Montfarine\\nZ:Transcrit et/ou corrig? par Michel BELLON - 2005-07-24\\nZ:Pour toute observation mailto:galouvielle@free.fr\\nM: 4/4\\nL: 1/8\\nQ:1/4=186\\nFGF B=AG G=AG F2F FGF {F}F2E EFE|\\n{E}E2D FGF B=AG G=AG {F}F2F FED C2G D2E|F3 {F}F/2 ED E3/2D/2|\\nEC FE E2 DC|DC C2 GD2E|F3F/2F/2 DE FD|EC B,C D2 B,G|\\ncB =A2 FG2E|F3F GF B=A|GG =AG F2 FF|GF F/2F3/2 EE FE|\\nE/2E3/2 DF GF B=A|GG =AG F/2F3/2 FF|ED C2 GD2E|F3F/2F/2 ED E3/2D/2|\\nEC FE E2 DC|DC C2 GD2E|F3F/2F/2 DE FD|EC B,C D2 B,G|\\ncB =A2 FF G=A|B3\\nG2_A G/2G3/2-|GF/2F/2 ED F2 EB,|CD EF GB AG|\\nA3A GA F2|F/2F/2F EF D3/2B,/2 B,B,|CD EF GA GF|G3B/2B/2 AB G2|\\nGG/2G/2 FG E2 EB/2B/2|AG BA GG AB|c3c/2c3/2d f2|ed eG c2 BB|\\nAB dc BG AD|E3F GF BA|GG AG F2 FF|GF F/2F3/2 EE FE|\\nE/2E3/2 DF GF BA|GG AG F/2F3/2 FF|ED C2 GD2E|F2- F/2\\n<end>'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(config['epochs']):\n",
    "    #TODO : randomize the songs here\n",
    "    \n",
    "    \n",
    "    #train\n",
    "    model.train()\n",
    "    for song in train_songs:\n",
    "        checkpoint = torch.load(config['saved_path'])\n",
    "\n",
    "        #set states to 0 at the beginning of each song\n",
    "        hidden_state = torch.zeros((config['num_layers'], 1, config['input_dim'])).to(computing_device)\n",
    "        cell_state = torch.zeros((config['num_layers'], 1, config['input_dim'])).to(computing_device)\n",
    "        hidden = (hidden_state, cell_state)\n",
    "\n",
    "        #restore the model's weights \n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "        #train here\n",
    "        model.zero_grad()\n",
    "    \n",
    "        #TODO : fix this using the dataloader\n",
    "        output, h = model(inputs, hidden)\n",
    "        \n",
    "        loss = criterion(output.squeeze(), labels.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "\n",
    "        #save model\n",
    "        torch.save({\n",
    "                'model_state_dict': net.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "            }, config['saved_path'])\n",
    "    #validation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for song in val_songs:\n",
    "            \n",
    "            #set states to 0 at the beginning of each song\n",
    "            hidden_state = torch.zeros((config['num_layers'], 1, config['input_dim'])).to(computing_device)\n",
    "            cell_state = torch.zeros((config['num_layers'], 1, config['input_dim'])).to(computing_device)\n",
    "            hidden = (hidden_state, cell_state)\n",
    "            \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
