{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from model import *\n",
    "from dataloader import *\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import torch.nn.functional as F\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {}\n",
    "config['epochs'] = 20\n",
    "config['temperature'] = 0.7\n",
    "config['num_neurons'] = 100\n",
    "config['num_layers'] = 1\n",
    "config['input_dim'] = None\n",
    "config['learning_rate'] = 0.001\n",
    "config['saved_path'] = 'Saved_weights_baseline.pth'\n",
    "config['validation_loss_path'] = 'val_loss_baseline.out' \n",
    "config['training_loss_path'] = 'training_loss_baseline.out' \n",
    "config['early_stop_epoch'] = 3\n",
    "config['early_stopping'] = False\n",
    "config['max_song_length'] = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is supported\n"
     ]
    }
   ],
   "source": [
    "# Check if your system supports CUDA\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "# Setup GPU optimization if CUDA is supported\n",
    "if use_cuda:\n",
    "    computing_device = torch.device(\"cuda\")\n",
    "    extras = {\"num_workers\": 1, \"pin_memory\": True}\n",
    "    print(\"CUDA is supported\")\n",
    "else: # Otherwise, train on the CPU\n",
    "    computing_device = torch.device(\"cpu\")\n",
    "    extras = False\n",
    "    print(\"CUDA NOT supported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read in saved\n",
      "dict_keys(['4', 'A', '<', 't', '\\t', '8', 'v', 'b', '@', '!', '^', 'K', ')', '9', 'o', 'z', 'y', 'V', 'Q', '3', 'u', '0', 'c', '\\\\', 'r', 'U', '+', 'p', ':', 'L', 'T', '6', '_', 'm', 'N', 'w', 'D', '>', 'i', ' ', '}', ',', 'X', 'g', 'I', 'k', 'a', '{', 'O', 'E', '*', 'x', '-', 'q', 'J', '1', '/', 'P', '.', 'Z', '7', 'd', '$', 'h', 'C', 'M', '~', 'n', '#', '?', '\"', '\\n', ']', '|', '&', 'F', \"'\", '[', 'W', 's', 'S', 'B', '2', 'e', 'G', 'j', 'l', '5', '=', 'f', 'H', 'R', 'Y', '(', '%'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "95"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_file = open('train.txt', 'r')\n",
    "train_songs = []\n",
    "\n",
    "val_file = open('val.txt', 'r')\n",
    "val_songs = []\n",
    "\n",
    "test_file = open('test.txt', 'r')\n",
    "test_songs = []\n",
    "\n",
    "\n",
    "if not os.path.exists('one_hot_decode.pkl') or not os.path.exists('one_hot_encode.pkl'):  \n",
    "    print('creating new')\n",
    "    all_characters = train_file.read()\n",
    "    unique_characters = list(set(all_characters))\n",
    "\n",
    "    print((unique_characters))\n",
    "\n",
    "\n",
    "    #create one hot encodings for each unique character in the alphabet of the training data\n",
    "    one_hot_dict_encode = {}\n",
    "    one_hot_dict_decode = {}\n",
    "    index = 0\n",
    "    for unique_character in unique_characters:\n",
    "        current_encoding = np.zeros(config['input_dim'])\n",
    "        current_encoding[index] = 1\n",
    "\n",
    "        one_hot_dict_encode[unique_character] = current_encoding\n",
    "        one_hot_dict_decode[tuple(current_encoding)] = unique_character\n",
    "\n",
    "        index += 1\n",
    "\n",
    "\n",
    "    #start token\n",
    "    current_encoding = np.zeros(config['input_dim'])\n",
    "    current_encoding[93] = 1\n",
    "\n",
    "    one_hot_dict_encode['$'] = current_encoding\n",
    "    one_hot_dict_decode[tuple(current_encoding)] = '$'\n",
    "\n",
    "    #end song token\n",
    "    current_encoding = np.zeros(config['input_dim'])\n",
    "    current_encoding[94] = 1\n",
    "\n",
    "    one_hot_dict_encode['%'] = current_encoding\n",
    "    one_hot_dict_decode[tuple(current_encoding)] = '%'\n",
    "    \n",
    "    f = open(\"one_hot_decode.pkl\",\"wb\")\n",
    "    pickle.dump(one_hot_dict_decode, f)\n",
    "    f.close()\n",
    "    \n",
    "    f = open(\"one_hot_encode.pkl\", \"wb\")\n",
    "    pickle.dump(one_hot_dict_encode, f)\n",
    "    f.close()\n",
    "else : \n",
    "    print('read in saved')\n",
    "    f = open(\"one_hot_decode.pkl\",\"rb\")\n",
    "    one_hot_dict_decode = pickle.load(f)\n",
    "    f.close()\n",
    "    \n",
    "    f = open(\"one_hot_encode.pkl\", \"rb\")\n",
    "    one_hot_dict_encode = pickle.load(f)\n",
    "    f.close()\n",
    "    \n",
    "config['input_dim'] = len(one_hot_dict_decode)\n",
    "\n",
    "print(one_hot_dict_encode.keys())\n",
    "\n",
    "train_file = open('train.txt', 'r')\n",
    "train_songs = []\n",
    "\n",
    "val_file = open('val.txt', 'r')\n",
    "val_songs = []\n",
    "\n",
    "test_file = open('test.txt', 'r')\n",
    "test_songs = []\n",
    "\n",
    "\n",
    "#split the songs into their own strings, while including start and end tags\n",
    "song = []\n",
    "for line in train_file:\n",
    "    for character in line:\n",
    "        song.append(one_hot_dict_encode[character])\n",
    "\n",
    "        if character == '%':\n",
    "            song.append(one_hot_dict_encode['\\n'])\n",
    "            train_songs.append(song)\n",
    "            song = []\n",
    "    \n",
    "song = []\n",
    "for line in val_file:\n",
    "    for character in line:\n",
    "        song.append(one_hot_dict_encode[character])\n",
    "\n",
    "        if character == '%':\n",
    "            song.append(one_hot_dict_encode['\\n'])\n",
    "            val_songs.append(song)\n",
    "            song = []\n",
    "\n",
    "song = []\n",
    "for line in test_file:\n",
    "    for character in line:\n",
    "        song.append(one_hot_dict_encode[character])\n",
    "\n",
    "        if character == '%':\n",
    "            song.append(one_hot_dict_encode['\\n'])\n",
    "            test_songs.append(song)\n",
    "            song = []   \n",
    "            \n",
    "            \n",
    "len(one_hot_dict_decode)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|\n"
     ]
    }
   ],
   "source": [
    "a = np.zeros(config['input_dim'])\n",
    "a[73] = 1\n",
    "print(one_hot_dict_decode[tuple(a)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Lstm(\n",
       "   (lstm_layer): LSTM(95, 100, dropout=0.2)\n",
       "   (fc): Linear(in_features=100, out_features=95, bias=True)\n",
       " ), Adam (\n",
       " Parameter Group 0\n",
       "     amsgrad: False\n",
       "     betas: (0.9, 0.999)\n",
       "     eps: 1e-08\n",
       "     lr: 0.001\n",
       "     weight_decay: 0\n",
       " ))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Lstm(config['input_dim'], config['num_neurons'], config['num_layers']).to(computing_device)\n",
    "\n",
    "    \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=config['learning_rate'])\n",
    "\n",
    "if not os.path.exists(config['saved_path']):\n",
    "    torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "    }, config['saved_path'])\n",
    "    \n",
    "    np.savetxt(config['training_loss_path'], np.array([0,0]))\n",
    "    np.savetxt(config['validation_loss_path'], np.array([0,0]))\n",
    "    \n",
    "model, optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPPPPOCCCHHHHH 1\n",
      "epoch 1 with train error 1.0933928489685059\n",
      "epoch 1 with val error 1.6117006540298462\n",
      "EPPPPOCCCHHHHH 2\n",
      "epoch 2 with train error 1.0845848321914673\n",
      "epoch 2 with val error 1.6113781929016113\n",
      "EPPPPOCCCHHHHH 3\n",
      "epoch 3 with train error 1.073896884918213\n",
      "epoch 3 with val error 1.6332435607910156\n",
      "EPPPPOCCCHHHHH 4\n",
      "epoch 4 with train error 1.0691072940826416\n",
      "epoch 4 with val error 1.607514500617981\n",
      "EPPPPOCCCHHHHH 5\n",
      "epoch 5 with train error 1.05618417263031\n",
      "epoch 5 with val error 1.6394963264465332\n",
      "EPPPPOCCCHHHHH 6\n",
      "epoch 6 with train error 1.0503875017166138\n",
      "epoch 6 with val error 1.6211785078048706\n",
      "EPPPPOCCCHHHHH 7\n",
      "epoch 7 with train error 1.0453078746795654\n",
      "epoch 7 with val error 1.6021947860717773\n",
      "EPPPPOCCCHHHHH 8\n",
      "epoch 8 with train error 1.0355521440505981\n",
      "epoch 8 with val error 1.6222515106201172\n",
      "EPPPPOCCCHHHHH 9\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-3ea8e296efeb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0;31m#forward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/music-generation/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, hidden)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mis_size_one\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    562\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_packed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 564\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward_tensor\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    541\u001b[0m         \u001b[0munsorted_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 543\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    544\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munsorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward_impl\u001b[0;34m(self, input, hx, batch_sizes, max_batch_size, sorted_indices)\u001b[0m\n\u001b[1;32m    524\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m             result = _VF.lstm(input, hx, self._get_flat_weights(), self.bias, self.num_layers,\n\u001b[0;32m--> 526\u001b[0;31m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[1;32m    527\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m             result = _VF.lstm(input, batch_sizes, hx, self._get_flat_weights(), self.bias,\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#for early stopping\n",
    "num_times_incraesed = 0\n",
    "prev_val_loss = float(\"inf\")\n",
    "\n",
    "\n",
    "#restore the model's weights \n",
    "checkpoint = torch.load(config['saved_path'])\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "\n",
    "for epoch in range(config['epochs']):\n",
    "    print('EPPPPOCCCHHHHH ' + str(epoch + 1))\n",
    "    \n",
    "    total_loss = 0\n",
    "\n",
    "    #for early stopping\n",
    "    old_net_weights = model.state_dict()\n",
    "    old_optimizer = optimizer.state_dict()\n",
    "    \n",
    "    #metrics for train and val loss\n",
    "    training_losses = np.genfromtxt(config['training_loss_path'])\n",
    "    validation_losses = np.genfromtxt(config['validation_loss_path'])\n",
    "\n",
    "    #Shuffle the songs \n",
    "    random.shuffle(train_songs)\n",
    "    \n",
    "    #train\n",
    "    model.train()\n",
    "    for song in train_songs:\n",
    "\n",
    "        #set states to 0 at the beginning of each song\n",
    "        hidden_state = torch.zeros((config['num_layers'], 1, config['num_neurons'])).to(computing_device)\n",
    "        hidden_state = hidden_state.float()\n",
    "        cell_state = torch.zeros((config['num_layers'], 1, config['num_neurons'])).to(computing_device)\n",
    "        cell_state = cell_state.float()\n",
    "        hidden = (hidden_state, cell_state)\n",
    "\n",
    "        \n",
    "        #encode the characters to their respective one hot encoding\n",
    "        encoded_inputs = song\n",
    "        \n",
    "        song_loss = 0\n",
    "        #train\n",
    "        num_minibatches = math.ceil(len(encoded_inputs)/100)\n",
    "        for i in range(num_minibatches):\n",
    "            model.zero_grad()\n",
    "\n",
    "            chunk, targets = MyDataset(encoded_inputs)[i]\n",
    "           \n",
    "            \n",
    "            \n",
    "            if len(chunk) == 0:\n",
    "                break\n",
    "            \n",
    "            #to computing device\n",
    "            chunk = chunk.to(computing_device)\n",
    "            targets = targets.to(computing_device)\n",
    "            \n",
    "            #forward\n",
    "            output, hidden = model(chunk, hidden)\n",
    "            \n",
    "\n",
    "            \n",
    "            #loss\n",
    "            targets = targets.argmax(dim=1)\n",
    "            loss = criterion(output, targets)\n",
    "            song_loss += loss\n",
    "            \n",
    "            #backprop\n",
    "            loss.backward(retain_graph=True)\n",
    "            optimizer.step()\n",
    "            \n",
    "        total_loss += song_loss/num_minibatches\n",
    "      \n",
    "    #calculate training loss\n",
    "    average_epoch_loss = total_loss/len(train_songs)\n",
    "    print('epoch ' + str(epoch + 1) + ' with train error '+ str(average_epoch_loss.cpu().item()))\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "    total_loss = 0\n",
    "    #validation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for song in val_songs:\n",
    "            song_loss = 0\n",
    "            \n",
    "            #set states to 0 at the beginning of each song\n",
    "            hidden_state = torch.zeros((config['num_layers'], 1, config['num_neurons'])).to(computing_device)\n",
    "            hidden_state = hidden_state.float()\n",
    "            cell_state = torch.zeros((config['num_layers'], 1, config['num_neurons'])).to(computing_device)\n",
    "            cell_state = cell_state.float()\n",
    "            hidden = (hidden_state, cell_state)\n",
    "\n",
    "\n",
    "            #encode the characters to their respective one hot encoding\n",
    "            encoded_inputs = song\n",
    "\n",
    "\n",
    "            #val\n",
    "            num_minibatches = math.ceil(len(encoded_inputs)/100)\n",
    "            for i in range(num_minibatches):\n",
    "\n",
    "                chunk, targets = MyDataset(encoded_inputs)[i]\n",
    "                \n",
    "\n",
    "                if len(chunk) == 0:\n",
    "                    break\n",
    "\n",
    "                #to computing device\n",
    "                chunk = chunk.to(computing_device)\n",
    "                targets = targets.to(computing_device)\n",
    "\n",
    "                #forward\n",
    "                output, hidden = model(chunk, hidden)\n",
    "\n",
    "                targets = targets.argmax(dim=1)\n",
    "                \n",
    "#                 print('hi')\n",
    "#                 print(output.squeeze().argmax(dim=1))\n",
    "\n",
    "#                 print('mom')\n",
    "#                 print(targets)\n",
    "                loss = criterion(output, targets)\n",
    "                song_loss += loss\n",
    "                \n",
    "            total_loss += song_loss/num_minibatches\n",
    "\n",
    "                \n",
    "    #calculate training loss\n",
    "    average_val_epoch_loss = total_loss/len(val_songs)\n",
    "    print('epoch ' + str(epoch + 1) + ' with val error '+ str(average_val_epoch_loss.cpu().item()))\n",
    "    \n",
    "    \n",
    "    if config['early_stopping']:\n",
    "        #early stopping\n",
    "        if average_val_epoch_loss > prev_val_loss:\n",
    "            print('keeping old weights')\n",
    "            num_times_incraesed += 1\n",
    "            model.load_state_dict(old_net_weights)\n",
    "            optimizer.load_state_dict(old_optimizer)\n",
    "        else : \n",
    "            print('val is less than previous')\n",
    "            num_times_incraesed = 0\n",
    "            prev_val_loss = average_val_epoch_loss\n",
    "\n",
    "        if num_times_incraesed >= config['early_stop_epoch']:\n",
    "            print('early stopping triggered')\n",
    "            break       \n",
    "            \n",
    "            \n",
    "    #save model and loss\n",
    "    torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "    }, config['saved_path'])\n",
    "    \n",
    "    np.savetxt(config['training_loss_path'], np.append(training_losses, average_epoch_loss.cpu().item()))\n",
    "    np.savetxt(config['validation_loss_path'], np.append(validation_losses, average_val_epoch_loss.cpu().item()))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:51: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(RNN(\n",
       "   (rnn): RNN(95, 100, dropout=0.2)\n",
       "   (fc): Linear(in_features=100, out_features=95, bias=True)\n",
       " ), Adam (\n",
       " Parameter Group 0\n",
       "     amsgrad: False\n",
       "     betas: (0.9, 0.999)\n",
       "     eps: 1e-08\n",
       "     lr: 0.001\n",
       "     weight_decay: 0\n",
       " ))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_model = RNN(config['input_dim'], config['num_neurons'], config['num_layers']).to(computing_device)\n",
    "\n",
    "    \n",
    "rnn_criterion = nn.CrossEntropyLoss()\n",
    "rnn_optimizer = torch.optim.Adam(rnn_model.parameters(), lr=config['learning_rate'])\n",
    "\n",
    "if not os.path.exists(config['saved_path'] + '_rnn'):\n",
    "    torch.save({\n",
    "        'model_state_dict': rnn_model.state_dict(),\n",
    "        'optimizer_state_dict': rnn_optimizer.state_dict(),\n",
    "    }, config['saved_path']  + '_rnn')\n",
    "    \n",
    "    np.savetxt(config['training_loss_path'] + '_rnn', np.array([0,0]))\n",
    "    np.savetxt(config['validation_loss_path'] + '_rnn', np.array([0,0]))\n",
    "    \n",
    "rnn_model, rnn_optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPPPPOCCCHHHHH 1\n",
      "epoch 1 with train error 2.553476095199585\n",
      "epoch 1 with val error 2.4413230419158936\n",
      "EPPPPOCCCHHHHH 2\n",
      "epoch 2 with train error 1.9926903247833252\n",
      "epoch 2 with val error 2.132091522216797\n",
      "EPPPPOCCCHHHHH 3\n",
      "epoch 3 with train error 1.852763295173645\n",
      "epoch 3 with val error 2.049252510070801\n",
      "EPPPPOCCCHHHHH 4\n",
      "epoch 4 with train error 1.7767468690872192\n",
      "epoch 4 with val error 1.9801504611968994\n",
      "EPPPPOCCCHHHHH 5\n",
      "epoch 5 with train error 1.7135109901428223\n",
      "epoch 5 with val error 2.0715765953063965\n",
      "EPPPPOCCCHHHHH 6\n",
      "epoch 6 with train error 1.6840397119522095\n",
      "epoch 6 with val error 1.9413748979568481\n",
      "EPPPPOCCCHHHHH 7\n",
      "epoch 7 with train error 1.6453713178634644\n",
      "epoch 7 with val error 1.957262635231018\n",
      "EPPPPOCCCHHHHH 8\n",
      "epoch 8 with train error 1.6245723962783813\n",
      "epoch 8 with val error 1.9191571474075317\n",
      "EPPPPOCCCHHHHH 9\n",
      "epoch 9 with train error 1.6055363416671753\n",
      "epoch 9 with val error 1.8921295404434204\n",
      "EPPPPOCCCHHHHH 10\n",
      "epoch 10 with train error 1.588417410850525\n",
      "epoch 10 with val error 1.9744529724121094\n",
      "EPPPPOCCCHHHHH 11\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-55fd0f50d48f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m#backprop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m             \u001b[0mrnn_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \"\"\"\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#for early stopping\n",
    "num_times_incraesed = 0\n",
    "prev_val_loss = float(\"inf\")\n",
    "\n",
    "\n",
    "#restore the model's weights \n",
    "checkpoint = torch.load(config['saved_path'] + '_rnn')\n",
    "rnn_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "rnn_optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "\n",
    "for epoch in range(config['epochs']):\n",
    "    print('EPPPPOCCCHHHHH ' + str(epoch + 1))\n",
    "    \n",
    "    total_loss = 0\n",
    "\n",
    "    #for early stopping\n",
    "    old_net_weights = rnn_model.state_dict()\n",
    "    old_optimizer = rnn_optimizer.state_dict()\n",
    "    \n",
    "    #metrics for train and val loss\n",
    "    training_losses = np.genfromtxt(config['training_loss_path'] + '_rnn')\n",
    "    validation_losses = np.genfromtxt(config['validation_loss_path'] + '_rnn')\n",
    "\n",
    "    #Shuffle the songs \n",
    "    random.shuffle(train_songs)\n",
    "    \n",
    "    #train\n",
    "    rnn_model.train()\n",
    "    for song in train_songs:\n",
    "\n",
    "        #set states to 0 at the beginning of each song\n",
    "        hidden_state = torch.zeros((config['num_layers'], 1, config['num_neurons'])).to(computing_device)\n",
    "        hidden_state = hidden_state.float()\n",
    "        hidden = hidden_state\n",
    "\n",
    "        \n",
    "        #encode the characters to their respective one hot encoding\n",
    "        encoded_inputs = song\n",
    "        \n",
    "        song_loss = 0\n",
    "        #train\n",
    "        num_minibatches = math.ceil(len(encoded_inputs)/100)\n",
    "        for i in range(num_minibatches):\n",
    "            rnn_model.zero_grad()\n",
    "\n",
    "            chunk, targets = MyDataset(encoded_inputs)[i]\n",
    "           \n",
    "            \n",
    "            \n",
    "            if len(chunk) == 0:\n",
    "                break\n",
    "            \n",
    "            #to computing device\n",
    "            chunk = chunk.to(computing_device)\n",
    "            targets = targets.to(computing_device)\n",
    "            \n",
    "            #forward\n",
    "            output, hidden = rnn_model(chunk, hidden)\n",
    "            \n",
    "\n",
    "            \n",
    "            #loss\n",
    "            targets = targets.argmax(dim=1)\n",
    "            loss = rnn_criterion(output, targets)\n",
    "            song_loss += loss\n",
    "            \n",
    "            #backprop\n",
    "            loss.backward(retain_graph=True)\n",
    "            rnn_optimizer.step()\n",
    "            \n",
    "        total_loss += song_loss/num_minibatches\n",
    "      \n",
    "    #calculate training loss\n",
    "    average_epoch_loss = total_loss/len(train_songs)\n",
    "    print('epoch ' + str(epoch + 1) + ' with train error '+ str(average_epoch_loss.cpu().item()))\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "    total_loss = 0\n",
    "    #validation\n",
    "    rnn_model.eval()\n",
    "    with torch.no_grad():\n",
    "        for song in val_songs:\n",
    "            song_loss = 0\n",
    "            \n",
    "            #set states to 0 at the beginning of each song\n",
    "            hidden_state = torch.zeros((config['num_layers'], 1, config['num_neurons'])).to(computing_device)\n",
    "            hidden_state = hidden_state.float()\n",
    "            hidden = hidden_state\n",
    "\n",
    "\n",
    "            #encode the characters to their respective one hot encoding\n",
    "            encoded_inputs = song\n",
    "\n",
    "\n",
    "            #val\n",
    "            num_minibatches = math.ceil(len(encoded_inputs)/100)\n",
    "            for i in range(num_minibatches):\n",
    "\n",
    "                chunk, targets = MyDataset(encoded_inputs)[i]\n",
    "                \n",
    "\n",
    "                if len(chunk) == 0:\n",
    "                    break\n",
    "\n",
    "                #to computing device\n",
    "                chunk = chunk.to(computing_device)\n",
    "                targets = targets.to(computing_device)\n",
    "\n",
    "                #forward\n",
    "                output, hidden = rnn_model(chunk, hidden)\n",
    "\n",
    "                targets = targets.argmax(dim=1)\n",
    "                \n",
    "#                 print('hi')\n",
    "#                 print(output.squeeze().argmax(dim=1))\n",
    "\n",
    "#                 print('mom')\n",
    "#                 print(targets)\n",
    "                loss = rnn_criterion(output, targets)\n",
    "                song_loss += loss\n",
    "                \n",
    "            total_loss += song_loss/num_minibatches\n",
    "\n",
    "                \n",
    "    #calculate training loss\n",
    "    average_val_epoch_loss = total_loss/len(val_songs)\n",
    "    print('epoch ' + str(epoch + 1) + ' with val error '+ str(average_val_epoch_loss.cpu().item()))\n",
    "    \n",
    "    \n",
    "    if config['early_stopping']:\n",
    "        #early stopping\n",
    "        if average_val_epoch_loss > prev_val_loss:\n",
    "            print('keeping old weights')\n",
    "            num_times_incraesed += 1\n",
    "            rnn_model.load_state_dict(old_net_weights)\n",
    "            rnn_optimizer.load_state_dict(old_optimizer)\n",
    "        else : \n",
    "            print('val is less than previous')\n",
    "            num_times_incraesed = 0\n",
    "            prev_val_loss = average_val_epoch_loss\n",
    "\n",
    "        if num_times_incraesed >= config['early_stop_epoch']:\n",
    "            print('early stopping triggered')\n",
    "            break       \n",
    "            \n",
    "            \n",
    "    #save model and loss\n",
    "    torch.save({\n",
    "        'model_state_dict': rnn_model.state_dict(),\n",
    "        'optimizer_state_dict': rnn_optimizer.state_dict(),\n",
    "    }, config['saved_path'] + '_rnn')\n",
    "    \n",
    "    np.savetxt(config['training_loss_path'] + '_rnn', np.append(training_losses, average_epoch_loss.cpu().item()))\n",
    "    np.savetxt(config['validation_loss_path'] + '_rnn', np.append(validation_losses, average_val_epoch_loss.cpu().item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.44132304 2.13209152 2.04925251 1.98015046 2.0715766  1.9413749\n",
      " 1.95726264 1.91915715 1.89212954 1.97445297]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fbe303b6ef0>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3deXTU1f3/8efNvieErGQh7MENgbCJCARr1Vqr1qpttWpVtGrV1v5a+z1fu3xtv/1WrW2tWvetdakL7q1WhQIuIGFV9jUhkIRAViDr5P7++EwCwUACZPLJzLwe58xJMnOZeTMHXrlzP3cx1lpERMT/hbhdgIiI9A4FuohIgFCgi4gECAW6iEiAUKCLiAQIBbqISIDoNtCNMTnGmHnGmLXGmNXGmFsP026GMWaFt8383i9VRESOxHQ3D90YkwlkWmuXGWPigaXABdbaNQe1SQI+Ac621pYYY9Kstbt8WbiIiHTWbQ/dWltmrV3m/b4eWAtkHdLsO8Aca22Jt53CXESkj4UdTWNjTB4wFlh8yEMjgXBjzH+AeODP1tpnj/RcKSkpNi8v72heXkQk6C1dunS3tTa1q8d6HOjGmDjgVeA2a21dF88zHpgFRAOfGmMWWWs3HPIcs4HZALm5uRQVFfX8byEiIhhjig/3WI9muRhjwnHC/Dlr7ZwumpQC71pr91lrdwMLgDGHNrLWPmqtLbDWFqSmdvkLRkREjlFPZrkY4AlgrbX2vsM0ewOYZowJM8bEAJNwxtpFRKSP9GTIZSpwBfC5MWaF977/AnIBrLUPW2vXGmPeBVYBbcDj1tovfFGwiIh0rdtAt9Z+BJgetLsHuKc3ihIRkaOnlaIiIgFCgS4iEiAU6CIiAcLvAn1DRT13vb2GplaP26WIiPQrfhfoO6obeOKjrSzeUuV2KSIi/YrfBfqUYQOJCg9h7jptFyMicjC/C/So8FCmDkth7rpddLdTpIhIMPG7QAeYmZ9GSdV+Nlfuc7sUEZF+w28DHWDuugqXKxER6T/8MtCzkqLJz4jXOLqIyEH8MtABCvPTWLKtmtqGFrdLERHpF/w60D1tloUbK90uRUSkX/DbQB+bO4CkmHANu4iIePltoIeGGGaMTOU/6yvxtGn6ooiI3wY6QOHodKr2NbOytMbtUkREXOfXgT59RCqhIYZ5GnYREfHvQE+MCWd87gA+XKtAFxHx60AHKBydxpqyOsprG90uRUTEVf4f6N5Vo/PWq5cuIsHN7wN9RFocWUnRGnYRkaDn94FujGHW6DQ+3rSbxhYdeiEiwcvvAx2czboaWjws2rLH7VJERFwTEIE+Zahz6IWmL4pIMAuIQI8KD+X04SnMXa9DL0QkeAVEoIMz7LK9qoFNu/a6XYqIiCsCJtALOw690LCLiAQn/wv03RvhrdugtbnT3ZmJ0YzOTFCgi0jQ8r9Ar94GS5+CpU9/6aHC/FSKiqup3a9DL0Qk+PhfoA8/EwafDgvuhqbO4+WF+el42iwLdOiFiAQh/wt0Y+DMX8G+Slj0UKeHTs1JIjk2QtMXRSQo+V+gA+RMgPzz4OP7Yd/ujrtDQwzTR6Yyb/0uHXohIkHHPwMdYNYvoGUfLLyv092F+WlU729hxXYdeiEiwaXbQDfG5Bhj5hlj1hpjVhtjbj1C2wnGGI8x5uLeLbMLqaPg1O/AksegpqTj7jNGOodezF1X4fMSRET6k5700FuB2621o4HJwE3GmBMObWSMCQV+D7zXuyUewYyfAwbm/a7jrsTocMYPHsDcdbowKiLBpdtAt9aWWWuXeb+vB9YCWV00/SHwKtB3VyQTs2HidbDyBahY03H3rPw01pbVUVbb0GeliIi47ajG0I0xecBYYPEh92cBFwIP91ZhPTbtdoiMh7l3ddylVaMiEox6HOjGmDicHvht1tq6Qx7+E/Aza+0RNyQ3xsw2xhQZY4oqK3tpSCQmGabeAuv/CSWLABieFkdOcrSmL4pIUOlRoBtjwnHC/Dlr7ZwumhQALxpjtgEXAw8ZYy44tJG19lFrbYG1tiA1NfU4yj7E5BshLh0++BVYizGGwlFpfLxpjw69EJGg0ZNZLgZ4Alhrrb2vqzbW2iHW2jxrbR7wCnCjtfb1Xq30SCJiYfpPoeRT2Phv4MChF5/q0AsRCRI96aFPBa4ACo0xK7y3c40xNxhjbvBxfT037koYMAQ++DW0eZg8dCDR4aEadhGRoBHWXQNr7UeA6ekTWmuvOp6CjlloOBT+N7x6DXz+ClFjLmXq8BTmrtvFr893hmFERAKZ/64U7cqJF0HGKTDvN9DaRGF+GqXVDWzUoRciEgQCK9BDQpyNu2pKoOgpTV8UkaASWIEOMKwQ8qbBgnvIiGrhhMwE5q5VoItI4Au8QDcGzvw17N8Nnz5IYX4aS0t06IWIBL7AC3SA7PEw+nz45C+clReCp80yX4deiEiAC8xAByi8E1r2c9KWx0mOjWDuWu2+KCKBLXADPXUkjL2ckKInuXBIK/M3VOrQCxEJaIEb6ADT7wATwtXNz3sPvah2uyIREZ8J7EBPzIKJs8kqeYsTQkv4ULNdRCSABXagA5z+I0xUAnfFvab56CIS0AI/0GOSYeptjG9aTFzFEnbW6NALEQlMgR/oAJNuoDUmnTvCX9RsFxEJWMER6BExhM68g4KQDVQtf9PtakREfCI4Ah0w465gT2QOZ1c8QmNTs9vliIj0uqAJdELDqSj4CSNNKVvnPul2NSIivS54Ah0YOv27fGGHkrnsPmhtcrscEZFeFVSBHhURzr8zbyCppQK75HG3yxER6VVBFegAg8adw0eeE/HMvxca69wuR0Sk1wRdoM/MT+P3rd8mrLEKPn3A7XJERHpN0AV6ekIUbZmn8knUNPjkAdir1aMiEhiCLtABZuWncWfdBdjWRlhwj9vliIj0iqAM9Jn5aWxuy6R48EVQ9BRUbXW7JBGR4xaUgT4mO4mBsRE8EXophITCvP91uyQRkeMWlIEeEmKYMSqNt7Za2iZeD5+/DOWfu12WiMhxCcpAByjMT6NmfwsrBl8NUQnw4f+4XZKIyHEJ2kCfNjKFsBDD+1ub4PQfw8Z/w7aP3S5LROSYBW2gJ0SFMyEvmXnrdsHE2RCfCR/8EqzOHRUR/xS0gQ7OsMu68np27Dcw4w4oXQLr/+l2WSIixyS4A310GoBzNN2pl8PAEc5YepvH5cpERI5eUAf60JRYBg+McYZdQsNg1p1QuQ5WvuB2aSIiRy2oA90Yw8xRaXy8aTcNzR4YfT4MGgfzfgctjW6XJyJyVII60AFmjU6jqbWNT7fsBmPgzF9BXSloe10R8TPdBroxJscYM88Ys9YYs9oYc2sXbb5rjFnlvX1ijBnjm3J738QhycREhPLhWu8mXUOnw7BCWHgvNNa6W5yIyFHoSQ+9FbjdWjsamAzcZIw54ZA2W4Hp1tpTgLuAR3u3TN+JDAvl9OEpzFu3C9s+ZXHWL6GhGj75i7vFiYgchW4D3VpbZq1d5v2+HlgLZB3S5hNrbbX3x0VAdm8X6kuzRqexs7aR9RX1zh2DToUTL4JPH4T6CneLExHpoaMaQzfG5AFjgcVHaHYN8K9jL6nvzRzlTF/sGHYBKPxv8DTDgrtdqkpE5Oj0ONCNMXHAq8Bt1touz24zxszECfSfHebx2caYImNMUWVl5bHU6xNpCVGclJXgTF9sN3AYjPseLH0aqra4VpuISE/1KNCNMeE4Yf6ctXbOYdqcAjwOfMNau6erNtbaR621BdbagtTU1GOt2ScK89NZVlJN9b7mA3dO/xmERsDc37pXmIhID/VklosBngDWWmvvO0ybXGAOcIW1dkPvltg3CvPTaLMwf8NBnxziM2DyD+CLV6BspXvFiYj0QE966FOBK4BCY8wK7+1cY8wNxpgbvG1+AQwEHvI+XuSrgn3llKxEUuIinG0ADnbaLRCVpO11RaTfC+uugbX2I8B00+Za4NreKsoN7YdevL+mglZPG2Gh3t910Ukw7XZ4/07YuhCGTHO3UBGRwwj6laIHK8xPo7ahhWUlNZ0fmHgdJGRpe10R6dcU6AeZNsI59OJLwy7h0c72ujuWwtq33ClORKQbCvSDxEeFM3FIMnPXdbGYaMx3IGUkzL0LPK19X5yISDcU6IcozE9jQ8VeSqv3d34gNAxm/QJ2b4CVz7tTnIjIESjQD1GY76wanXfosAtA/nmQVeDdXrehjysTETkyBfohhqbGkTcwhg+7CvT27XXrd8Jnj/V1aSIiR6RA78LM/DQ+3bzHOfTiUEOmwfAzYeEfoKHmy4+LiLhEgd6FWfnpNLW28cnm3Ydp8AtorIGP/9y3hYmIHIECvQsThyQTGxHa9bALQOYYOPlb8NEf4ZVroHJ93xYoItIFBXoXIsJCmDYitfOhF4f62n1w+m2w/l/w4CRvsPvlNjYiEiAU6IdRmJ9GWW0j68rru24QleBcIL1tFUy91RvsE+HVa2H3xr4sVUQEUKAf1ox8Z3vfL60aPVRsCnzl195gvwXWveMN9usU7CLSpxToh5EWH8Up2YndB3q72BT4yv/AbZ/DlJth3dtOsM+ZDbs3+bZYEREU6Ec0c1Qay0qqqTr40IvuxKbAWXfBratgyk2w5k14cALMuV7BLiI+pUA/gsL8NKyF+Rt62Es/WFwqnPUbZyhm8o2w5g0n2F+7AfZs7v1iRSToKdCP4OSsRFLiIpm77jjOP41Lg6/+9kCwr34dHpgAr/1AwS4ivUqBfgQhIYaZo1KZv34XrZ6243uy9mC/daVzrN3qOQp2EelVCvRuFOanUdfYytLi6t55wvh0b7Cvgkk3HAj212+Eqi298xoiEpQU6N04fUQK4aGGueuPYRz9SOLT4ez/dXrsk66HL16FvxTA6zcp2EXkmCjQu9Fx6MXaXg70jhfIgLN/5wT7xNnw+ctOsL9xE1Rt9c1rikhAUqD3QGF+Oht37WV71f7uGx+r+Aw45/+8wX4drHoZHiiAN26G6m2+e91AsnUBPPctWPmi25WIuEKB3gMdh1709rBLVxIy4ZzfO8FecA2segn+Mh7e/CFUF/v+9f1R5Xp4/lJ45utOqL92PbzzE2g9ivUDIgFAgd4DQ1JiGZISy4e+GnbpSkImnHs33LoCCr7v9Dr/Mg7evEXB3m7vLnj7R/DQFCj+xNlb5/9thtN+CEseg2fOg7oyt6sU6TMK9B4qzE/j0y172N/cxwdEJwyCc++BW1bA+Kth5QsHgr2mpG9r6S+a98P8e+D+sbDsWZhwLdyyHE7/EUTGOQu6Ln4Kyr+AR6dD8aduVyzSJxToPVSYn0Zzaxsfb9rjTgGJWfC1ezsH+/3j4K1bg6fH3uaB5c85Q1DzfgNDZ8CNi51PMrEpnduedBFc+wFExDk99cWPwOG2QhYJEAr0HpqQl0xcZFjPN+vylY5gXw7jr4QVz8P9p8IL34HNc6HtOBdA9Veb58IjZ8AbNzrDUVe/C5c9BynDD/9n0k+A6+bC8K/Av37qbLvQ7MML2yIuC3O7AH/hHHqR0nHohTHG3YISs+Frf3CGGZY8AcuegfXvwMDhzhDEmG9DdJK7NfaGijXw/p2w6QNIyoWLn4QTL3IO7O6J6CS47HlYeC/M+1+oWA2X/g2Sh/i2bhEXqId+FGbmp1Fe18iasjq3SzkgMRvO/CX8aA1c+AhEJcG7d8B9o53hmPIv3K7w2NSXOzN7Hp4KpUvgrN/CzUVw0jd7HubtQkJg+k/hOy9BbQk8OgM2fuCTskXcpEA/CjNGOYdezHN72KUr4VEw5jK47kOY/R+nF7vyRScQnzzHWYnqD9P4mvbCvN85FzxXvACTfuBcNzjtZgiLPL7nHnmW894kZsNzF8OCewJ3iEqCkjnsmZk+VlBQYIuKilx57ePxjQc+IjTEMOfGqW6X0r39VbD877Dkcagphrh0GH+Vc0sY5HZ1nbV5nFrn/Rb2VsCJF8KsX0Dy0N5/reb98NYtzqrcUV+DC/8KUYm9/zoiPmCMWWqtLejqMfXQj9LM/DSWb69hz94mt0vpXkyycyzeLcud4YaMU2D+3fDHk+Cl78HWhe7P/LAWNr4PD5/uhOyAPLjmffjW074Jc4CIGLjoMTj797DhXXisEHat881rifQhBfpRmpWf7j304jj2SO9rIaEw8qtw+StwyzJn+94t853pfA9NcXrwTYc5DNuXylbB3y5whj9aGuCSZ+H770HORN+/tjEw+Qa48i1orHNCffVrvn9dER/qNtCNMTnGmHnGmLXGmNXGmFu7aGOMMfcbYzYZY1YZY8b5plz3nTgogdT4SD7sj+PoPZE81Nm+98dr4fwHIDQc3rkd/jAa/vn/nGX0vla7w9kH/pEzoGyl01O+6TM44RtHf8HzeOVNhevnO1McX74K/n0nePp48ZhIL+nJtMVW4HZr7TJjTDyw1BjzvrV2zUFtzgFGeG+TgL96vwac9kMv/vVFOS2eNsJD/fRDTkQMjLsCxl7uzCL57DFY+jR89igMOQMmXAejzoXQXpzZ2lQPH/0JPn0QrMdZoj/tdvenVyYMgqvegXd/Dp/cD2UrnJWmhy5WEunnuk0ja22ZtXaZ9/t6YC2QdUizbwDPWsciIMkYk9nr1fYThfnp1PfmoRduMsYZ4vjmY87Ux8I7Yc8WeOkK+PMpzkyQvcf5acTT6gzr3D/WmQ8++jxnCuJZd7kf5u3CIuG8++AbD0LJYnhkOuxY5nZVIkflqLqXxpg8YCyw+JCHsoDtB/1cypdDP2B0HHrhr8MuhxOXCmf8xNnp8dK/O4uU5v4G7jsBXr3WCbqjuYhqLaz/F/x1ijOskzLSWbn5zcdhwGDf/T2Ox9jL4Zr3nF90T54Ny/7mdkUiPdbjQDfGxAGvArdZaw9dWdPVwOeX/ucbY2YbY4qMMUWVlX50UfEQcZFhTBoykPfXVNDY4nG7nN4XGgajvw5Xvgk3LXF2e9zwHjx5FjwyDZY+0/0S+p3Lne1sX7jMCfbLXnCGNbLG983f4XgMGguz58PgKfDmzc4CrVY/mNUkQa9H89CNMeHA28B71tr7unj8EeA/1toXvD+vB2ZYaw+7d6m/zkNv986qMm56fhnjBw/gkSvGkxJ3nIte+rumvbDqH87Qya41zrztsVc4YT9w2IF2Ndth7l1O25iBMOPnzrz30HDXSj9mbR748H/g4z85v4gu+Zuzl46Ii440D73bQDfOpiXPAFXW2tsO0+ZrwM3AuTgXQ++31h5x7pm/BzrAvz4v40cvrSAlLpKnrprAiPR4t0vyPWuh+GPnIuq6t6GtFYaf6QT79s9g0V+9UwJvhNNvC4wFO2vecA7xDo92LpYOmeZ2RRLEjjfQTwcWAp8D7euk/wvIBbDWPuwN/QeAs4H9wNXW2iOmdSAEOsDK7TVc+2wRjc0eHvzuOM4Ymep2SX2nrsyZGbP0adhbDhhn+4HC/3aW1weSyvXw4nedA7zPusv5heX2Bm3in9o8zi0s4pj++HEFuq8ESqAD7Kxp4JpnithQUc+vzj+RKyb30wt+vuJpgU0fOiGecZLb1fhOYx28/gPnk8lJ34Tz/wIRsW5XJf6izePsqTT/bmcY8rSbj+lptPTfxwYlRfPyDVOYMTKVO1//gl+/tRpPWxAdphAaDqPODuwwB4hKcMbRZ/0CvpgDj58Jeza7XZX0d55WWPkPeHAizLnOmSKbMtInL6VA7yVxkWE8+r0Crjl9CE99vI3rni1ib5NWHAackBBnMdTlr0J9GTw6E9a/63ZV0h95Wp0dTx+aBK/NhrAoZzrw9QudnT99QEMuPvDc4mJ+8cZqRqTF8cRVE8hKina7JPGF6m3wj8uh/HOYfgdM/5kT+G5qbXZ2q2y/tTY60zAHDNGYf1/xtMIXrzhDK1WbIf1kmPEzZ2fPXvj3oTF0FyzcWMmNzy0jMiyUx68s4NScfrIiUnpXSwO8dRusehFGfBUuegSiB/Tua1gLTXVQX+FcfN67yzkApD2067337S2HhsOsXo5Lh5xJkDsZciZD5in+OZW0P/O0OlsyL7jbuXiecbLzi37Uub36i16B7pJNu+q5+ukl7Kpr4r5LTuVrpwTsbgjBzVpnfv67d0BijvOxuifXEzytsH9350Cub+9dHxzcu6C14ct/PjQS4tOdsI5Lh/iMA9/HpTuPmRAoLYLti6FkkbMvPkBYtDO3PneSE/A5E3r/F1Gw8LTC5y8522S0B/mMnztB7oNPRQp0F+3Z28T1f1tKUXE1PzlrJDfNHO7+eaTiGyWLnH3mm+rh3HudnS0PHv7o6GF7v9+/G2wXJyZFJR0I5LgMiEvrHNbx3vuiko4+MOrKYPsiZxuH7YucLYytd7Vz6ugDAZ87ScM03WkP8vl3Q/VW57yBGXf4LMjbKdBd1tTq4Y5XP+e15Tu4aFwWv7voZCLDQt0uS3yhvhxeutIJy4OZUCeEDw7kuIyDetgZBx4Pj+q7epv3wY6lBwJ++xJoqnUei0t3Nm7LmQy5UzRM087T6qyEXnDPQUH+cxh1Tp/8AlSg9wPWWv4ydxP3vb+BiXnJPHzFeJJjj21hgfRzrc2w8d9OMLeHdcxA9y+Y9kRbG1SudT5taJimM0+LN8jvdYI8c4wT5CPP7tNPMgr0fuStlTu5/eWVZCZG8cSVExieFud2SSJHVld2INyDcZimI8jvcWY2ZZ7qDK30cZC3U6D3M8tKqpn9bBHNrW389fLxTB2ugxTEjxxpmCY27aCAn+wMRxzjEnfXeVqceeQL7nE+pWSe6u2Rf9XVX1oK9H5oe9V+rn2miM2Ve7nrgpP49sRct0sSOTY9GabJGgdpoyF1FKSMgsh+/MnU0wIrX3CGVmqKnXn8M34OI87qF58+FOj9VH1jCzc/v5z5Gyq5btoQ7jhnNKEh7v+DETlu7cM07QFf/jm0tRx4PDHHCffU/ANfU0a6e4JVR5DfAzUlMGicN8i/0i+CvJ0CvR9r9bRx19treObTYs4cnc6fLzuV2MhePMdTpD/wtDoXEivXQ+W6A193b3BWs7aLz+wc8Kn5zi12oO9qa212gnzhvf06yNsp0P3AM59s49dvrSY/I4EnriogM1HbBUgQaPM4IdpV0DfvPdAuJqVzb779a1zasYduazOsfB4W/AFqS5yhoRk/d/b374dB3k6B7ifmrd/FD59fTkxEKE9cOYGTswPgcAiRY2Et1O3oHPLtXxtrD7SLSuoi6EdBQtbhQ/lLQV7gDfJZ/TrI2ynQ/cj68nq+//QS9uxr4k+XnsrZJ2m7AJEO1jorbSvXfzno9+8+0C4iHlJHHjJGPwK2zIeFf4Da7X4X5O0U6H6msr6J654tYsX2Gn52dj43TB+q7QJEurNv95dDvnK99zStg2RPcOaRD/OvIG93pEDX1bd+KDU+khdnT+YnL6/k9++uY+vuvfzmgpOJCPODlYYibolNcW55Uzvf31DjjMlXroOkXBgy3S+DvCcU6P1UVHgo9182lqEpsdw/dxMlVft5+PLxJMX46SINEbdEJ3n3pDniufUBQV2+fiwkxPDjs0bxx0vHsKy4hgsf+oStu/e5XZaI9FMKdD9w4dhsnrtuErUNLVzw4Md8unmP2yWJSD+kQPcTE/KSef3GqaTGR/K9JxfzUtF2t0sSkX5Gge5HcgfG8OoPTmPy0IH89JVV/N+/1tHW5s4sJRHpfxTofiYxOpwnr5rAdyfl8vD8zdz43DIamj1ulyUi/YAC3Q+Fh4bwmwtO4s7zTuC9NeWce/9CXvyshMYWBbtIMFOg+yljDNecPoRnrp5IbGQod8z5nGl3z+Oh/2yitqGl+ycQkYCjlaIBwFrLJ5v38PD8zSzcuJvYiFC+PTGX758+hEFJ2uRLJJBo6X8QWb2zlscWbOGtVWUY4PxTB3H9GcMYlRHvdmki0gsU6EGotHo/T3y0lRc/205Di4eZo1K5fvowJg1J1r4wIn5MgR7Eqvc18/dFxTz9yTb27GtmTE4SN5wxlLNOzNDpSCJ+SIEuNLZ4eGVpKY8v3MK2PfvJGxjDtdOGcvH4bKLCQ90uT0R6SIEuHTxtln+vLufh+ZtZWVrLwNgIrjotjyumDNbGXyJ+4LgC3RjzJHAesMtae1IXjycCfwdycXZvvNda+1R3RSnQ3WWtZfHWKh6Zv5l56yuJiQjl0gk5XHP6ELIHxLhdnogcxvEG+hnAXuDZwwT6fwGJ1tqfGWNSgfVAhrW2+UjPq0DvP9aV1/Hogi28uWInFvj6KZnMPmMYJwxKcLs0ETnEkQK924VF1toFQNWRmgDxxpk6Eedt23oshYo78jMSuO+SU1nw05l8f2oe76+p4Nz7F3LFE4v5eNNu3BqWE5Gj06MxdGNMHvD2YXro8cCbQD4QD1xqrX2nu+dUD73/qm1o4bnFxTz18TYq65s4KSuB2WcM49yTMggL1eJiETcd90XRbgL9YmAq8GNgGPA+MMZaW9dF29nAbIDc3NzxxcXFPf9bSJ9ravXw+vIdPLJgC1sq95E9IJrrpg3lWwXZxETosCsRN/g60N8B/s9au9D781zgDmvtZ0d6TvXQ/Udbm+WDtRU8PH8zy0pqGBATzvem5PG9KYMZGBfpdnkiQcXXh0SXALOAhcaYdGAUsKUXnlf6iZAQw1knZnDWiRkUbavi4flb+POHG3lkwWYuKcjh2tOHkjtQM2NE3NaTWS4vADOAFKAC+CUQDmCtfdgYMwh4GsgEDE5v/e/dvbB66P5t0656Hl2whdeW78DTZjnn5Ey+PzWPcbkDtLWAiA9pYZH4TEVdI099vI3nFhVT39TKsNRYLinI4cJxWaTFR7ldnkjAUaCLz+1tauWfq8p4qWg7RcXVhIYYZo5K45KCbGbmpxGu2TEivUKBLn1qc+VeXi4q5dVlpVTWN5ESF8FF47L51vhsRqRrG1+R46FAF1e0etqYv6GSl4q28+HaXbS2WcbmJnFJQQ7nnZJJfFS42yWK+B0Furhu994mXl++g38s2c7GXXuJCg/h3JMzuaQgR3u0ixwFBbr0G9ZaVpbW8lLRdt5asZP6plYGD4zhW+Oz+eb4bDITdWSeyJEo0KVfamj28O7qMl5aUsqnW/YQYmDaiFQuKcjhzCa8keQAAArgSURBVBPSiAzTPu0ih1KgS79XvGcfrywt5ZWlpZTVNpIUE84Fp2ZxSUGOdn0UOYgCXfyGp83y0abdvFS0nfdXV9DsaePkrES+VZDNN8ZkkRijC6kS3BTo4peq9zXzxood/KOolLVldUSEhXD2iRlcUpDDacMGEqIzUSUIKdDF732xo5aXi7bz+oqd1Da0kJUUzcXjs7l4fDY5ydpHRoKHAl0CRmOLh/fXVPBS0XY+2rQba2Hq8IFcUpDDV0/M0IHXEvAU6BKQdtQ08OrSUl4q2k5pdQPxUWGcP2YQU4enkJ8Rz+CBsYRqWEYCjAJdAlpbm2XR1j28XFTKPz8vo6m1DYCo8BBGpseTnxFPfkaC8zUzgeTYCJcrFjl2CnQJGo0tHjZW7GVdeR3ryuudr2X17Nl34MzytPhIRmXEMzrTCflRGfEMT4vTvHfxC74+4EKk34gKD+Xk7EROzk7sdH9lfVNHuLcH/dMfb6PZ4/TmQ0MMw1Jjyc9I8Ia906vPTIzStgTiNxToEhRS4yNJjU9l2ojUjvtaPW1s3b2vU09+aXE1b67c2dEmPiqM0RkJ5Gc6Pfn2wI+L1H8d6X/0r1KCVlhoCCPS4xmRHs/XxwzquL+2oYUNFfWsK2sftqlnzrId7G1q7WiTmxzj9OS94/KjMuLJ00VYcZkCXeQQidHhTMhLZkJecsd91lpKqxucgC+rY5038D9cW0Gb9zJU+0XYUenO+Py4wQM4cVCCDveQPqOLoiLHobuLsFHhIYzNGcCEvAEU5CUzNjdJ+8DLcdFFUREfOdxF2PLaRpYWV7NkWxVFxVU8MG8TbRZCDIzOTGBCXjIFeQMoGJxMRqLOXpXeoR66SB/Y29TK8pJqlmyrpmhbFctLamho8QCQkxzNhMHJFOQlMyFvAMNS47RPjRyWeugiLouLDGPaiAOzbFo8bazZWceSbVUsLa5mwcZK5izfAUBSTDjjcwd0BPzJ2YmaIy89okAXcUF4aAhjcpIYk5PEtdOci67Fe/Y7QzTbqllSXMWH63YBEBEWwpjsxI6AH5+brG2EpUsachHpp3bvbWJpsTNEs2RbNV/sqKXVO6VmVHo8BXkDOsbis5KitQAqSGjpv0gAaGj2sGJ7jRPwxdUsK67umBufmRjV0YMvGJzMqIx4zYkPUBpDFwkA0RGhTBk2kCnDBgLO6U7ryuucIZptVSzZWsVb3lWu8ZFhjBs8gLG5SQweGEP2gBiyB0STHh+lC64BTD10kQBhrWVHTUNHwBdtq2Z9RX2nNuGhhqyk6I6Az0l2vjq3GFLjIhX4/Zx66CJBwBjjDeoYLhibBTgLn0qrGyit3u/96ny/vbqBD9ZWsHtvc6fniAgLITspmixvwOckHwj/7AHRpMZFaqy+H1OgiwSwqPBQhqfFMTwtrsvHG5o97KjZz/aqL4f+ezvLqdrXOfAjw0I6evOde/jO14GxEQp8FynQRYJYdEQow9PiGZ4W3+Xj+5pa2VHj7dUfEvqrSmuo3t/S+fnCQzsN4bSHflZSNIOSnMDXkI7vKNBF5LBiI8MYmR7PyPSuA7++scUJ/KoDQzntob+spIbahs6BHxEaQmZSFJmJUQxKimZQohP0mUlRZCVFk5kYpb1ujoMCXUSOWXxUOPkZ4eRnJHT5eF1jC6VVDeyoaaCs1vm6s6aRspoGFm3eQ0V9E542e8hzhnmDPorMpOiOoG//BZCRGEVEmHaw7Eq3gW6MeRI4D9hlrT3pMG1mAH8CwoHd1trpvVmkiPinhKhwThgUzgmDug78Vk8bu+qbvGHvBP3OmgZ21jays6aBlaW1XxrHNwZS4iK9Ae8N+oO+z0yKIiU2OGfr9KSH/jTwAPBsVw8aY5KAh4CzrbUlxpi03itPRAJZWGhIRyCPH9x1m4ZmD2W1Ts/eCXsn9MtqG1lfUc9/1ld2bHTWLiI0hIzEKAYlRXUa1slMjCI9wbklxwTeeH63gW6tXWCMyTtCk+8Ac6y1Jd72u3qnNBER58Lt0NQ4hqZ2PVPHWkvN/hZv0Dd2DO2UeX8BLN5aRXld45eGdsJDDWnxUaQnRJKRGEVafBQZic7P7aGfkRBFrB8dN9gblY4Ewo0x/wHigT9ba7vszYuI9DZjDANiIxgQG8GJgxK7bNM+tFNe10hFbSMVdY2U1zWxq66R8rpG1pfXs2DD7k7HDLaLiwzrCPmMhCjSEqLIaA/9ROe+1PjIfnEyVW8EehgwHpgFRAOfGmMWWWs3HNrQGDMbmA2Qm5vbCy8tItK9g4d2jmRvUysVdY0dt/Lapk4/L95axa76Rlo8nXv7xsDA2Eint98R+t7efmIU6d7e/4CYcJ/O0++NQC/FuRC6D9hnjFkAjAG+FOjW2keBR8FZ+t8Lry0i0mviIsOIS41j2GGGdwDa2ixV+5sPCvomymsb2VXfSHltI2W1jazYXtNxDOHBIkJDSEuI5MopeVx3xtBer783Av0N4AFjTBgQAUwC/tgLzysi0u+EhBhS4iJJiYs87BAPQHNrG7vqncB3evuNVNQ7Qz5pCZE+qa0n0xZfAGYAKcaYUuCXONMTsdY+bK1da4x5F1gFtAGPW2u/8Em1IiJ+IiIspGNvnb7Sk1ku3+5Bm3uAe3qlIhEROSbuX5YVEZFeoUAXEQkQCnQRkQChQBcRCRAKdBGRAKFAFxEJEAp0EZEAYax1ZwW+MaYSKD7GP54C7O7Fcvyd3o/O9H4coPeis0B4PwZba1O7esC1QD8expgia22B23X0F3o/OtP7cYDei84C/f3QkIuISIBQoIuIBAh/DfRH3S6gn9H70ZnejwP0XnQW0O+HX46hi4jIl/lrD11ERA7hd4FujDnbGLPeGLPJGHOH2/W4yRiTY4yZZ4xZa4xZbYy51e2a3GaMCTXGLDfGvO12LW4zxiQZY14xxqzz/huZ4nZNbjHG/Mj7f+QLY8wLxpgot2vyBb8KdGNMKPAgcA5wAvBtY8wJ7lblqlbgdmvtaGAycFOQvx8AtwJr3S6in/gz8K61Nh/nWMigfF+MMVnALUCBtfYkIBS4zN2qfMOvAh2YCGyy1m6x1jYDLwLfcLkm11hry6y1y7zf1+P8h81ytyr3GGOyga8Bj7tdi9uMMQnAGcATANbaZmttjbtVuSoMiPYelRkD7HS5Hp/wt0DPArYf9HMpQRxgBzPG5AFjgcXuVuKqPwE/xTkKMdgNBSqBp7xDUI8bY2LdLsoN1todwL1ACVAG1Fpr/+1uVb7hb4Fuurgv6KfpGGPigFeB26y1dW7X4wZjzHnALmvtUrdr6SfCgHHAX621Y4F9QFBeczLGDMD5JD8EGATEGmMud7cq3/C3QC8Fcg76OZsA/ejUU8aYcJwwf85aO8ftelw0FTjfGLMNZyiu0Bjzd3dLclUpUGqtbf/E9gpOwAejM4Gt1tpKa20LMAc4zeWafMLfAn0JMMIYM8QYE4FzYeNNl2tyjTHG4IyRrrXW3ud2PW6y1v7cWpttrc3D+Xcx11obkL2wnrDWlgPbjTGjvHfNAta4WJKbSoDJxpgY7/+ZWQToBeIwtws4GtbaVmPMzcB7OFeqn7TWrna5LDdNBa4APjfGrPDe91/W2n+6WJP0Hz8EnvN2frYAV7tcjyustYuNMa8Ay3Bmhi0nQFeMaqWoiEiA8LchFxEROQwFuohIgFCgi4gECAW6iEiAUKCLiAQIBbqISIBQoIuIBAgFuohIgPj/7DLEqb1g3EMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_losses = np.genfromtxt(config['training_loss_path']+ '_rnn')[2:]\n",
    "validation_losses = np.genfromtxt(config['validation_loss_path']+ '_rnn')[2:]\n",
    "print(validation_losses)\n",
    "\n",
    "x_axis = []\n",
    "for i in range(len(training_losses)):\n",
    "    x_axis.append(i)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(x_axis, training_losses)\n",
    "plt.plot(x_axis, validation_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.2623105  1.93900692 1.86721361 1.73471773 1.70964777 1.67382395\n",
      " 1.66307199 1.62063646 1.62720847 1.63149607 1.60833895 1.6112864\n",
      " 1.5962069  1.58226824 1.59238398 1.61996806 1.59337294 1.61170065\n",
      " 1.61137819 1.63324356 1.6075145  1.63949633 1.62117851 1.60219479\n",
      " 1.62225151]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f61a49dacc0>]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_losses = np.genfromtxt(config['training_loss_path'])[2:]\n",
    "validation_losses = np.genfromtxt(config['validation_loss_path'])[2:]\n",
    "print(validation_losses)\n",
    "\n",
    "x_axis = []\n",
    "for i in range(len(training_losses)):\n",
    "    x_axis.append(i)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(x_axis, training_losses)\n",
    "plt.plot(x_axis, validation_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Temperature 0.7 seems to work the best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":1\n",
      "T:John McBway\n",
      "O:France\n",
      "A:Provence\n",
      "R:Marche\n",
      "Z:Transcrit et/ou corrig? par Michel BELLON - 2005-07-26\n",
      "Z:Pour toute observation mailto:galouvielle@free.fr\n",
      "M:2/4\n",
      "L:1/8\n",
      "K:Gm\n",
      "GA BG | G2 GB | c2 c2 | d2 d2 | d2 dd | d2 d2 | d2 d2 | d2 d2 | d2 cB |\n",
      "A2 A2 | G2 GG | A2 A2 | A2 A2 | G3 :|\n",
      "|: d | e2 e2 | d2 d2 | d2 dd | e2 ed | c2 A2 | B2 Bz | G2 G2 | G2 A2 | B2 B2 | c2 A2 | G2 E2 | G2 E2 |\n",
      "A>B AG | A2 A2 | G4 | A4 | G>A B2 | G2 G2 | G2 G2 | G2 A2 | G2 G2 | A2 A2 | \n",
      "G2 GA | B2 A2 | G2 A2 | G4 ||\n",
      "P:Intro\n",
      "a | e2 de | d2 d2 | d2 d2 | d2 ed | c2 A2 | B2 c2 | B2 AG | A2 A2 | G2 AB | c2 c2 | A2 BA | G2 G2 :|\n",
      "%\n"
     ]
    }
   ],
   "source": [
    "#get first initial input\n",
    "output = torch.from_numpy(np.array(one_hot_dict_encode['X'])).float()[None,None,:].to(computing_device) \n",
    "                \n",
    "#init hidden state\n",
    "hidden_state = torch.zeros((config['num_layers'], 1, config['num_neurons'])).to(computing_device)\n",
    "hidden_state = hidden_state.float()\n",
    "cell_state = torch.zeros((config['num_layers'], 1, config['num_neurons'])).to(computing_device)\n",
    "cell_state = cell_state.float()\n",
    "hidden = (hidden_state, cell_state)\n",
    "\n",
    "\n",
    "new_song = []\n",
    "\n",
    "#generate music\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    while output.squeeze().argmax().item() != 94 : \n",
    "        output, hidden = model(output, hidden)\n",
    "        \n",
    "        softmax = F.softmax(output/config['temperature'])\n",
    "        \n",
    "        start = 0\n",
    "        partitions = []\n",
    "        \n",
    "        for i in softmax[0]:\n",
    "            partitions.append((start, start + i.item()))\n",
    "            start = start + i.item()\n",
    "        \n",
    "        roll = random.uniform(0, partitions[-1][1])\n",
    "        \n",
    "        \n",
    "        guess = 0\n",
    "        for partition in partitions:\n",
    "            if roll >= partition[0] and roll < partition[1]:\n",
    "                break\n",
    "            else : \n",
    "                guess += 1\n",
    "        \n",
    "\n",
    "        next_input = np.zeros(config['input_dim'])\n",
    "        next_input[guess] = 1\n",
    "        \n",
    "        new_song.append(next_input)\n",
    "        \n",
    "        \n",
    "        output = torch.from_numpy(next_input).float()[None, None, :].to(computing_device)\n",
    "        \n",
    "\n",
    "decoded_string = \"\"\n",
    "for encoding in new_song:\n",
    "#     print(one_hot_dict_decode[tuple(encoding)], end =\" \")\n",
    "    decoded_string += one_hot_dict_decode[tuple(encoding)]\n",
    "print(decoded_string)\n",
    "            \n",
    "        \n",
    "        \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
