{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from model import *\n",
    "from dataloader import *\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {}\n",
    "config['epochs'] = 100\n",
    "config['temperature'] = 1\n",
    "config['num_neurons'] = 100\n",
    "config['num_layers'] = 1\n",
    "config['input_dim'] = None\n",
    "config['learning_rate'] = 0.001\n",
    "config['saved_path'] = 'Saved_weights_baseline.pth'\n",
    "config['validation_loss_path'] = 'val_loss_baseline.out' \n",
    "config['training_loss_path'] = 'training_loss_baseline.out' \n",
    "config['early_stop_epoch'] = 3\n",
    "config['early_stopping'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is supported\n"
     ]
    }
   ],
   "source": [
    "# Check if your system supports CUDA\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "# Setup GPU optimization if CUDA is supported\n",
    "if use_cuda:\n",
    "    computing_device = torch.device(\"cuda\")\n",
    "    extras = {\"num_workers\": 1, \"pin_memory\": True}\n",
    "    print(\"CUDA is supported\")\n",
    "else: # Otherwise, train on the CPU\n",
    "    computing_device = torch.device(\"cpu\")\n",
    "    extras = False\n",
    "    print(\"CUDA NOT supported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['N', 'O', 'Q', 'z', '!', 'V', '\\\\', '~', 'y', '&', 'n', 'm', '\\t', 'T', 'w', '-', ',', 'W', 'o', ']', '[', '\"', 'M', ')', 's', 'H', 'i', '0', 'r', 'e', 'g', 'v', '@', 'u', '8', '#', 'q', 'X', 'a', 'R', '5', 'l', 'E', ' ', 'c', 'Y', 'k', 'D', 'J', 'p', '/', 'f', '^', '7', '=', '}', '|', '*', 'L', '+', 'd', 'h', 'K', 'S', '<', \"'\", 'U', 'A', 'x', ':', '.', '\\n', '4', '2', '?', 'F', 'P', 'b', '9', 'I', 't', '{', '>', 'Z', 'B', 'j', '1', 'C', '%', 'G', '3', '$', '_', '6', '(']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(95, 95)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_file = open('train.txt', 'r')\n",
    "train_songs = []\n",
    "\n",
    "val_file = open('val.txt', 'r')\n",
    "val_songs = []\n",
    "\n",
    "test_file = open('test.txt', 'r')\n",
    "test_songs = []\n",
    "\n",
    "\n",
    "    \n",
    "all_characters = train_file.read()\n",
    "unique_characters = list(set(all_characters))\n",
    "config['input_dim'] = len(unique_characters)\n",
    "\n",
    "print((unique_characters))\n",
    "\n",
    "\n",
    "#create one hot encodings for each unique character in the alphabet of the training data\n",
    "one_hot_dict_encode = {}\n",
    "one_hot_dict_decode = {}\n",
    "index = 0\n",
    "for unique_character in unique_characters:\n",
    "    current_encoding = np.zeros(config['input_dim'])\n",
    "    current_encoding[index] = 1\n",
    "    \n",
    "    one_hot_dict_encode[unique_character] = current_encoding\n",
    "    one_hot_dict_decode[tuple(current_encoding)] = unique_character\n",
    "    \n",
    "    index += 1\n",
    "    \n",
    "    \n",
    "#encode end of song token\n",
    "\n",
    "#start token\n",
    "current_encoding = np.zeros(config['input_dim'])\n",
    "current_encoding[93] = 1\n",
    "\n",
    "one_hot_dict_encode['$'] = current_encoding\n",
    "one_hot_dict_decode[tuple(current_encoding)] = '$'\n",
    "\n",
    "#end song token\n",
    "current_encoding = np.zeros(config['input_dim'])\n",
    "current_encoding[94] = 1\n",
    "\n",
    "one_hot_dict_encode['%'] = current_encoding\n",
    "one_hot_dict_decode[tuple(current_encoding)] = '%'\n",
    "\n",
    "\n",
    "train_file = open('train.txt', 'r')\n",
    "train_songs = []\n",
    "\n",
    "val_file = open('val.txt', 'r')\n",
    "val_songs = []\n",
    "\n",
    "test_file = open('test.txt', 'r')\n",
    "test_songs = []\n",
    "\n",
    "\n",
    "#split the songs into their own strings, while including start and end tags\n",
    "song = []\n",
    "for line in train_file:\n",
    "    for character in line:\n",
    "        song.append(one_hot_dict_encode[character])\n",
    "\n",
    "        if character == '%':\n",
    "            song.append(one_hot_dict_encode['\\n'])\n",
    "            train_songs.append(song)\n",
    "            song = []\n",
    "    \n",
    "song = []\n",
    "for line in val_file:\n",
    "    for character in line:\n",
    "        song.append(one_hot_dict_encode[character])\n",
    "\n",
    "        if character == '%':\n",
    "            song.append(one_hot_dict_encode['\\n'])\n",
    "            val_songs.append(song)\n",
    "            song = []\n",
    "\n",
    "song = []\n",
    "for line in test_file:\n",
    "    for character in line:\n",
    "        song.append(one_hot_dict_encode[character])\n",
    "\n",
    "        if character == '%':\n",
    "            song.append(one_hot_dict_encode['\\n'])\n",
    "            test_songs.append(song)\n",
    "            song = []   \n",
    "            \n",
    "            \n",
    "len(unique_characters), len(one_hot_dict_decode)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">\n"
     ]
    }
   ],
   "source": [
    "a = np.zeros(config['input_dim'])\n",
    "a[82] = 1\n",
    "print(one_hot_dict_decode[tuple(a)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Lstm(\n",
       "   (lstm_layer): LSTM(95, 100)\n",
       "   (fc): Linear(in_features=100, out_features=95, bias=True)\n",
       " ), Adam (\n",
       " Parameter Group 0\n",
       "     amsgrad: False\n",
       "     betas: (0.9, 0.999)\n",
       "     eps: 1e-08\n",
       "     lr: 0.001\n",
       "     weight_decay: 0\n",
       " ))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Lstm(config['input_dim'], config['num_neurons'], config['num_layers']).to(computing_device)\n",
    "\n",
    "    \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=config['learning_rate'])\n",
    "\n",
    "if not os.path.exists(config['saved_path']):\n",
    "    torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "    }, config['saved_path'])\n",
    "    \n",
    "    np.savetxt(config['training_loss_path'], np.array([0,0]))\n",
    "    np.savetxt(config['validation_loss_path'], np.array([0,0]))\n",
    "    \n",
    "model, optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPPPPOCCCHHHHH 1\n",
      "epoch 1 with train error 2.6265718936920166\n",
      "epoch 1 with val error 2.2819409370422363\n",
      "EPPPPOCCCHHHHH 2\n",
      "epoch 2 with train error 1.8208980560302734\n",
      "epoch 2 with val error 1.8868529796600342\n",
      "EPPPPOCCCHHHHH 3\n",
      "epoch 3 with train error 1.596938967704773\n",
      "epoch 3 with val error 1.789360523223877\n",
      "EPPPPOCCCHHHHH 4\n",
      "epoch 4 with train error 1.4789568185806274\n",
      "epoch 4 with val error 1.7459514141082764\n",
      "EPPPPOCCCHHHHH 5\n",
      "epoch 5 with train error 1.4047659635543823\n",
      "epoch 5 with val error 1.7023038864135742\n",
      "EPPPPOCCCHHHHH 6\n",
      "epoch 6 with train error 1.345504641532898\n",
      "epoch 6 with val error 1.6539688110351562\n",
      "EPPPPOCCCHHHHH 7\n",
      "epoch 7 with train error 1.3055180311203003\n",
      "epoch 7 with val error 1.6470122337341309\n",
      "EPPPPOCCCHHHHH 8\n",
      "epoch 8 with train error 1.2735228538513184\n",
      "epoch 8 with val error 1.6225864887237549\n",
      "EPPPPOCCCHHHHH 9\n",
      "epoch 9 with train error 1.2417042255401611\n",
      "epoch 9 with val error 1.6142029762268066\n",
      "EPPPPOCCCHHHHH 10\n",
      "epoch 10 with train error 1.217301845550537\n",
      "epoch 10 with val error 1.5992523431777954\n",
      "EPPPPOCCCHHHHH 11\n",
      "epoch 11 with train error 1.1982749700546265\n",
      "epoch 11 with val error 1.598770022392273\n",
      "EPPPPOCCCHHHHH 12\n",
      "epoch 12 with train error 1.178329586982727\n",
      "epoch 12 with val error 1.6056240797042847\n",
      "EPPPPOCCCHHHHH 13\n",
      "epoch 13 with train error 1.1622740030288696\n",
      "epoch 13 with val error 1.5908681154251099\n",
      "EPPPPOCCCHHHHH 14\n",
      "epoch 14 with train error 1.1454466581344604\n",
      "epoch 14 with val error 1.5898101329803467\n",
      "EPPPPOCCCHHHHH 15\n",
      "epoch 15 with train error 1.1318683624267578\n",
      "epoch 15 with val error 1.5803600549697876\n",
      "EPPPPOCCCHHHHH 16\n",
      "epoch 16 with train error 1.1194432973861694\n",
      "epoch 16 with val error 1.5713837146759033\n",
      "EPPPPOCCCHHHHH 17\n",
      "epoch 17 with train error 1.1073949337005615\n",
      "epoch 17 with val error 1.5709019899368286\n",
      "EPPPPOCCCHHHHH 18\n",
      "epoch 18 with train error 1.0988709926605225\n",
      "epoch 18 with val error 1.587145209312439\n",
      "EPPPPOCCCHHHHH 19\n",
      "epoch 19 with train error 1.088110089302063\n",
      "epoch 19 with val error 1.586005687713623\n",
      "EPPPPOCCCHHHHH 20\n",
      "epoch 20 with train error 1.0781219005584717\n",
      "epoch 20 with val error 1.6096383333206177\n",
      "EPPPPOCCCHHHHH 21\n",
      "epoch 21 with train error 1.0681391954421997\n",
      "epoch 21 with val error 1.6243867874145508\n",
      "EPPPPOCCCHHHHH 22\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-3ea8e296efeb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0;31m#backprop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \"\"\"\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#for early stopping\n",
    "num_times_incraesed = 0\n",
    "prev_val_loss = float(\"inf\")\n",
    "\n",
    "\n",
    "#restore the model's weights \n",
    "checkpoint = torch.load(config['saved_path'])\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "\n",
    "for epoch in range(config['epochs']):\n",
    "    print('EPPPPOCCCHHHHH ' + str(epoch + 1))\n",
    "    \n",
    "    total_loss = 0\n",
    "\n",
    "    #for early stopping\n",
    "    old_net_weights = model.state_dict()\n",
    "    old_optimizer = optimizer.state_dict()\n",
    "    \n",
    "    #metrics for train and val loss\n",
    "    training_losses = np.genfromtxt(config['training_loss_path'])\n",
    "    validation_losses = np.genfromtxt(config['validation_loss_path'])\n",
    "\n",
    "    #Shuffle the songs \n",
    "    random.shuffle(train_songs)\n",
    "    \n",
    "    #train\n",
    "    model.train()\n",
    "    for song in train_songs:\n",
    "\n",
    "        #set states to 0 at the beginning of each song\n",
    "        hidden_state = torch.zeros((config['num_layers'], 1, config['num_neurons'])).to(computing_device)\n",
    "        hidden_state = hidden_state.float()\n",
    "        cell_state = torch.zeros((config['num_layers'], 1, config['num_neurons'])).to(computing_device)\n",
    "        cell_state = cell_state.float()\n",
    "        hidden = (hidden_state, cell_state)\n",
    "\n",
    "        \n",
    "        #encode the characters to their respective one hot encoding\n",
    "        encoded_inputs = song\n",
    "        \n",
    "        song_loss = 0\n",
    "        #train\n",
    "        num_minibatches = math.ceil(len(encoded_inputs)/100)\n",
    "        for i in range(num_minibatches):\n",
    "            model.zero_grad()\n",
    "\n",
    "            chunk, targets = MyDataset(encoded_inputs)[i]\n",
    "           \n",
    "            \n",
    "            \n",
    "            if len(chunk) == 0:\n",
    "                break\n",
    "            \n",
    "            #to computing device\n",
    "            chunk = chunk.to(computing_device)\n",
    "            targets = targets.to(computing_device)\n",
    "            \n",
    "            #forward\n",
    "            output, hidden = model(chunk, hidden)\n",
    "            \n",
    "\n",
    "            \n",
    "            #loss\n",
    "            targets = targets.argmax(dim=1)\n",
    "            loss = criterion(output, targets)\n",
    "            song_loss += loss\n",
    "            \n",
    "            #backprop\n",
    "            loss.backward(retain_graph=True)\n",
    "            optimizer.step()\n",
    "            \n",
    "        total_loss += song_loss/num_minibatches\n",
    "      \n",
    "    #calculate training loss\n",
    "    average_epoch_loss = total_loss/len(train_songs)\n",
    "    print('epoch ' + str(epoch + 1) + ' with train error '+ str(average_epoch_loss.cpu().item()))\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "    total_loss = 0\n",
    "    #validation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for song in val_songs:\n",
    "            song_loss = 0\n",
    "            \n",
    "            #set states to 0 at the beginning of each song\n",
    "            hidden_state = torch.zeros((config['num_layers'], 1, config['num_neurons'])).to(computing_device)\n",
    "            hidden_state = hidden_state.float()\n",
    "            cell_state = torch.zeros((config['num_layers'], 1, config['num_neurons'])).to(computing_device)\n",
    "            cell_state = cell_state.float()\n",
    "            hidden = (hidden_state, cell_state)\n",
    "\n",
    "\n",
    "            #encode the characters to their respective one hot encoding\n",
    "            encoded_inputs = song\n",
    "\n",
    "\n",
    "            #val\n",
    "            num_minibatches = math.ceil(len(encoded_inputs)/100)\n",
    "            for i in range(num_minibatches):\n",
    "\n",
    "                chunk, targets = MyDataset(encoded_inputs)[i]\n",
    "                \n",
    "\n",
    "                if len(chunk) == 0:\n",
    "                    break\n",
    "\n",
    "                #to computing device\n",
    "                chunk = chunk.to(computing_device)\n",
    "                targets = targets.to(computing_device)\n",
    "\n",
    "                #forward\n",
    "                output, hidden = model(chunk, hidden)\n",
    "\n",
    "                targets = targets.argmax(dim=1)\n",
    "                \n",
    "#                 print('hi')\n",
    "#                 print(output.squeeze().argmax(dim=1))\n",
    "\n",
    "#                 print('mom')\n",
    "#                 print(targets)\n",
    "                loss = criterion(output, targets)\n",
    "                song_loss += loss\n",
    "                \n",
    "            total_loss += song_loss/num_minibatches\n",
    "\n",
    "                \n",
    "    #calculate training loss\n",
    "    average_val_epoch_loss = total_loss/len(val_songs)\n",
    "    print('epoch ' + str(epoch + 1) + ' with val error '+ str(average_val_epoch_loss.cpu().item()))\n",
    "    \n",
    "    \n",
    "    if config['early_stopping']:\n",
    "        #early stopping\n",
    "        if average_val_epoch_loss > prev_val_loss:\n",
    "            print('keeping old weights')\n",
    "            num_times_incraesed += 1\n",
    "            model.load_state_dict(old_net_weights)\n",
    "            optimizer.load_state_dict(old_optimizer)\n",
    "        else : \n",
    "            print('val is less than previous')\n",
    "            num_times_incraesed = 0\n",
    "            prev_val_loss = average_val_epoch_loss\n",
    "\n",
    "        if num_times_incraesed >= config['early_stop_epoch']:\n",
    "            print('early stopping triggered')\n",
    "            break       \n",
    "            \n",
    "            \n",
    "    #save model and loss\n",
    "    torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "    }, config['saved_path'])\n",
    "    \n",
    "    np.savetxt(config['training_loss_path'], np.append(training_losses, average_epoch_loss.cpu().item()))\n",
    "    np.savetxt(config['validation_loss_path'], np.append(validation_losses, average_val_epoch_loss.cpu().item()))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.28194094 1.88685298 1.78936052 1.74595141 1.70230389 1.65396881\n",
      " 1.64701223 1.62258649 1.61420298 1.59925234 1.59877002 1.60562408\n",
      " 1.59086812 1.58981013 1.58036005 1.57138371 1.57090199 1.58714521\n",
      " 1.58600569 1.60963833 1.62438679]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f2fa40ce470>]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_losses = np.genfromtxt(config['training_loss_path'])[2:]\n",
    "validation_losses = np.genfromtxt(config['validation_loss_path'])[2:]\n",
    "print(validation_losses)\n",
    "\n",
    "x_axis = []\n",
    "for i in range(len(training_losses)):\n",
    "    x_axis.append(i)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(x_axis, training_losses)\n",
    "plt.plot(x_axis, validation_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get first initial input\n",
    "# cell_state = torch.from_numpy(np.array(one_hot_enocode['X'])).float()[:,None,:] \n",
    "print(cell_state)\n",
    "                \n",
    "#init hidden state\n",
    "hidden_state = torch.zeros((config['num_layers'], 1, config['num_neurons'])).to(computing_device)\n",
    "hidden_state = hidden_state.float()\n",
    "cell_state = torch.zeros((config['num_layers'], 1, config['num_neurons'])).to(computing_device)\n",
    "cell_state = cell_state.float()\n",
    "hidden = (hidden_state, cell_state)\n",
    "\n",
    "#generate music\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    while True: \n",
    "        cell_state, hidden = model(cell_state.to(computing_device), hidden)\n",
    "        break\n",
    "        \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
