{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from model import *\n",
    "from dataloader import *\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {}\n",
    "config['epochs'] = 100\n",
    "config['temperature'] = 1\n",
    "config['num_neurons'] = 100\n",
    "config['num_layers'] = 1\n",
    "config['input_dim'] = None\n",
    "config['learning_rate'] = 0.001\n",
    "config['saved_path'] = 'Saved_weights.pth'\n",
    "config['validation_loss_path'] = 'val_loss.out' \n",
    "config['training_loss_path'] = 'training_loss.out' \n",
    "config['early_stop_epoch'] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is supported\n"
     ]
    }
   ],
   "source": [
    "# Check if your system supports CUDA\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "# Setup GPU optimization if CUDA is supported\n",
    "if use_cuda:\n",
    "    computing_device = torch.device(\"cuda\")\n",
    "    extras = {\"num_workers\": 1, \"pin_memory\": True}\n",
    "    print(\"CUDA is supported\")\n",
    "else: # Otherwise, train on the CPU\n",
    "    computing_device = torch.device(\"cpu\")\n",
    "    extras = False\n",
    "    print(\"CUDA NOT supported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['c', '7', '+', 'v', 'k', '\"', 'C', 'G', 'f', \"'\", 'y', 'p', 'H', '6', 'J', ',', 'X', '&', '1', 'l', '-', 'S', 't', '0', '@', 'i', 'j', 'I', 'u', ')', 'Q', 'b', 'N', 'Z', 'K', 'd', 'O', 'x', '!', 'q', 'M', '*', '#', 'T', '9', 'e', '3', 'w', 'B', '\\\\', '_', 'm', '^', ' ', 'g', '5', '<', 'U', ']', '~', 'n', '\\t', 'V', 'L', 'o', '4', 'r', '8', '/', 'z', 'a', '?', '\\n', '[', ':', '.', 'h', 'F', 'W', 'E', '=', 'A', '}', '{', '>', '|', '(', 'P', 'Y', '2', 'R', 's', 'D']\n"
     ]
    }
   ],
   "source": [
    "train_file = open('train.txt', 'r')\n",
    "train_file = train_file.read()\n",
    "train_songs = []\n",
    "\n",
    "val_file = open('val.txt', 'r')\n",
    "val_file = val_file.read()\n",
    "val_songs = []\n",
    "\n",
    "test_file = open('test.txt', 'r')\n",
    "test_file = test_file.read()\n",
    "test_songs = []\n",
    "\n",
    "#split the songs into their own strings, while including start and end tags\n",
    "for song in train_file.split('<start>')[1:]:\n",
    "    #remove \\n after <end> tag\n",
    "    train_songs.append('<start>' + song[:-1])\n",
    "    \n",
    "for song in val_file.split('<start>')[1:]:\n",
    "    #remove \\n after <end> tag\n",
    "    val_songs.append('<start>' + song[:-1])\n",
    "\n",
    "for song in test_file.split('<start>')[1:]:\n",
    "    #remove \\n after <end> tag\n",
    "    test_songs.append('<start>' + song[:-1])\n",
    "    \n",
    "    \n",
    "unique_characters = list(set(train_file))\n",
    "config['input_dim'] = len(unique_characters)\n",
    "\n",
    "#create one hot encodings for each unique character in the alphabet of the training data\n",
    "one_hot_dict_encode = {}\n",
    "one_hot_dict_decode = {}\n",
    "index = 0\n",
    "for unique_character in unique_characters:\n",
    "    current_encoding = np.zeros(len(unique_characters))\n",
    "    current_encoding[index] = 1\n",
    "    \n",
    "    one_hot_dict_encode[unique_character] = current_encoding\n",
    "    one_hot_dict_decode[tuple(current_encoding)] = unique_character\n",
    "    \n",
    "    index += 1\n",
    "\n",
    "\n",
    "print((unique_characters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Lstm(config['input_dim'], config['num_neurons'], config['num_layers']).to(computing_device)\n",
    "if not os.path.exists(config['saved_path']):\n",
    "    torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "    }, config['saved_path'])\n",
    "    \n",
    "    np.savetxt(config['training_loss_path'], np.array([0,0]))\n",
    "    np.savetxt(config['validation_loss_path'], np.array([0,0]))\n",
    "    \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=config['learning_rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPPPPOCCCHHHHH 1\n",
      "epoch 1 with train error 4.2929534912109375\n",
      "epoch 1 with val error 3.9062676429748535\n",
      "EPPPPOCCCHHHHH 2\n",
      "epoch 2 with train error 3.0241074562072754\n",
      "epoch 2 with val error 3.7579569816589355\n",
      "EPPPPOCCCHHHHH 3\n",
      "epoch 3 with train error 2.686026096343994\n",
      "epoch 3 with val error 3.5719480514526367\n",
      "EPPPPOCCCHHHHH 4\n",
      "epoch 4 with train error 2.507314920425415\n",
      "epoch 4 with val error 3.380596160888672\n",
      "EPPPPOCCCHHHHH 5\n",
      "epoch 5 with train error 2.382575750350952\n",
      "epoch 5 with val error 3.2898364067077637\n",
      "EPPPPOCCCHHHHH 6\n",
      "epoch 6 with train error 2.288663148880005\n",
      "epoch 6 with val error 3.228142738342285\n",
      "EPPPPOCCCHHHHH 7\n",
      "epoch 7 with train error 2.2203195095062256\n",
      "epoch 7 with val error 3.2012100219726562\n",
      "EPPPPOCCCHHHHH 8\n",
      "epoch 8 with train error 2.1560254096984863\n",
      "epoch 8 with val error 3.179741382598877\n",
      "EPPPPOCCCHHHHH 9\n",
      "epoch 9 with train error 2.1050281524658203\n",
      "epoch 9 with val error 3.20088529586792\n",
      "EPPPPOCCCHHHHH 10\n",
      "epoch 10 with train error 2.068643093109131\n",
      "epoch 10 with val error 3.155038595199585\n",
      "EPPPPOCCCHHHHH 11\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-5e330e36bf1e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \"\"\"\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#for early stopping\n",
    "num_times_incraesed = 0\n",
    "prev_val_loss = float(\"inf\")\n",
    "\n",
    "\n",
    "#restore the model's weights \n",
    "checkpoint = torch.load(config['saved_path'])\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "\n",
    "for epoch in range(config['epochs']):\n",
    "    old_net_weights = model.state_dict()\n",
    "    old_optimizer = optimizer.state_dict()\n",
    "    \n",
    "    training_losses = np.genfromtxt(config['training_loss_path'])\n",
    "    validation_losses = np.genfromtxt(config['validation_loss_path'])\n",
    "    epoch_loss = 0\n",
    "\n",
    "    print('EPPPPOCCCHHHHH ' + str(epoch + 1))\n",
    "    #TODO : randomize the songs here\n",
    "    \n",
    "    #train\n",
    "    model.train()\n",
    "    for song in train_songs:\n",
    "\n",
    "        #set states to 0 at the beginning of each song\n",
    "        hidden_state = torch.zeros((config['num_layers'], 1, config['num_neurons'])).to(computing_device)\n",
    "        hidden_state = hidden_state.float()\n",
    "        cell_state = torch.zeros((config['num_layers'], 1, config['num_neurons'])).to(computing_device)\n",
    "        cell_state = cell_state.float()\n",
    "        hidden = (hidden_state, cell_state)\n",
    "\n",
    "        \n",
    "        #encode the characters to their respective one hot encoding\n",
    "        encoded_inputs = [one_hot_dict_encode[character] for character in song]\n",
    "        \n",
    "        \n",
    "        #train\n",
    "        num_minibatches = math.ceil(len(encoded_inputs)/100)\n",
    "        for i in range(num_minibatches):\n",
    "            model.zero_grad()\n",
    "\n",
    "            chunk, targets = MyDataset(encoded_inputs)[i]\n",
    "            \n",
    "            if len(chunk) == 0:\n",
    "                break\n",
    "            \n",
    "            chunk = chunk.to(computing_device)\n",
    "            targets = targets.to(computing_device)\n",
    "            \n",
    "            output, hidden = model(chunk, hidden)\n",
    "            \n",
    "            loss = criterion(output, targets)\n",
    "            epoch_loss += loss\n",
    "            \n",
    "            loss.backward(retain_graph=True)\n",
    "            optimizer.step()\n",
    "      \n",
    "    #calculate training loss\n",
    "    average_epoch_loss = epoch_loss/num_minibatches/len(train_songs)\n",
    "    print('epoch ' + str(epoch + 1) + ' with train error '+ str(average_epoch_loss.cpu().item()))\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "    epoch_loss = 0\n",
    "    #validation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for song in val_songs:\n",
    "            #set states to 0 at the beginning of each song\n",
    "            hidden_state = torch.zeros((config['num_layers'], 1, config['num_neurons'])).to(computing_device)\n",
    "            hidden_state = hidden_state.float()\n",
    "            cell_state = torch.zeros((config['num_layers'], 1, config['num_neurons'])).to(computing_device)\n",
    "            cell_state = cell_state.float()\n",
    "            hidden = (hidden_state, cell_state)\n",
    "\n",
    "\n",
    "            #encode the characters to their respective one hot encoding\n",
    "            encoded_inputs = [one_hot_dict_encode[character] for character in song]\n",
    "\n",
    "\n",
    "            #val\n",
    "            num_minibatches = math.ceil(len(encoded_inputs)/100)\n",
    "            for i in range(num_minibatches):\n",
    "\n",
    "                chunk, targets = MyDataset(encoded_inputs)[i]\n",
    "\n",
    "                if len(chunk) == 0:\n",
    "                    break\n",
    "\n",
    "                chunk = chunk.to(computing_device)\n",
    "                targets = targets.to(computing_device)\n",
    "\n",
    "                output, hidden = model(chunk, hidden)\n",
    "\n",
    "                loss = criterion(output, targets)\n",
    "                epoch_loss += loss\n",
    "\n",
    "                \n",
    "    #calculate training loss\n",
    "    average_val_epoch_loss = epoch_loss/num_minibatches/len(val_songs)\n",
    "    print('epoch ' + str(epoch + 1) + ' with val error '+ str(average_val_epoch_loss.cpu().item()))\n",
    "    \n",
    "    \n",
    "    \n",
    "    #early stopping\n",
    "    if num_times_incraesed >= config['early_stop_epoch']:\n",
    "        print('early stopping triggered')\n",
    "        break\n",
    "    if N_minibatch_val_loss > prev_val_loss:\n",
    "        print('keeping old weights')\n",
    "        num_times_incraesed += 1\n",
    "        net.load_state_dict(old_net_weights)\n",
    "        optimizer.load_state_dict(old_optimizer)\n",
    "    else : \n",
    "        print('val is less than previous')\n",
    "        num_times_incraesed = 0\n",
    "        prev_val_loss = N_minibatch_val_loss\n",
    "            \n",
    "            \n",
    "            \n",
    "    #save model and loss\n",
    "    torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "    }, config['saved_path'])\n",
    "    \n",
    "    np.savetxt(config['training_loss_path'], np.append(training_losses, average_epoch_loss.cpu().item()))\n",
    "    np.savetxt(config['validation_loss_path'], np.append(validation_losses, average_val_epoch_loss.cpu().item()))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.29295349 3.02410746 2.6860261  2.50731492 2.38257575 2.28866315\n",
      " 2.22031951 2.15602541 2.10502815 2.06864309]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f75e06877f0>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_losses = np.genfromtxt(config['training_loss_path'])[2:]\n",
    "validation_losses = np.genfromtxt(config['validation_loss_path'])[2:]\n",
    "\n",
    "x_axis = []\n",
    "for i in range(len(training_losses)):\n",
    "    x_axis.append(i)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(x_axis, training_losses)\n",
    "plt.plot(x_axis, validation_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save({\n",
    "#         'model_state_dict': model.state_dict(),\n",
    "#         'optimizer_state_dict': optimizer.state_dict(),\n",
    "#     }, config['saved_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
